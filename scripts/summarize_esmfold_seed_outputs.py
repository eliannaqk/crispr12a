#!/usr/bin/env python3
"""Summarize ESMFold domain scores for selected seeds.

The script walks the PDB outputs generated by ``esmfold_domain_assessor.py``
so we can compute per-domain pLDDT statistics without rerunning ESMFold.
It writes two CSV reports under ``metrics``:
  * per-seed table capturing the best (highest total_mean_pLDDT) sequence
    together with its domain means; and
  * counts of sequences that exceed the seq1 reference per-domain thresholds.
"""
from __future__ import annotations

import argparse
import csv
import datetime as dt
import os
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Tuple

import numpy as np
import pandas as pd
from Bio import SeqIO  # type: ignore

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

import esmfold_domain_assessor as eda


@dataclass(frozen=True)
class SeedConfig:
    name: str
    fasta_path: Path
    pdb_dir: Path


DEFAULT_SEEDS: Dict[str, SeedConfig] = {
    "seed1": SeedConfig(
        name="seed1",
        fasta_path=Path(
            "/home/eqk3/project_pi_mg269/eqk3/crisprData/atlas/"
            "generated_sequences/run-20250828-193254-ba4000-sweep/generations/ba4000/by-seed/seed1/"
            "seed1.filtered_step7_pass.fasta"
        ),
        pdb_dir=Path("esmfold_seed_outputs/full_seed1/esm_pdbs_seed1_full"),
    ),
    "seed4": SeedConfig(
        name="seed4",
        fasta_path=Path("esmfold_seed_outputs/seed4_cluster_reps_full.fasta"),
        pdb_dir=Path("esmfold_seed_outputs/cluster_seed4_full/esm_pdbs_seed4_cluster"),
    ),
}


def parse_seed_specs(specs: Iterable[str]) -> Dict[str, SeedConfig]:
    out: Dict[str, SeedConfig] = {}
    for raw in specs:
        parts = raw.split(":", maxsplit=2)
        if len(parts) != 3:
            raise ValueError(
                f"Seed spec '{raw}' must look like name:/path/to/fasta:/path/to/pdb_dir"
            )
        name, fasta_path, pdb_dir = parts
        out[name] = SeedConfig(name=name, fasta_path=Path(fasta_path), pdb_dir=Path(pdb_dir))
    return out


def load_sequences(path: Path) -> Dict[str, str]:
    if not path.exists():
        raise FileNotFoundError(f"Missing FASTA file: {path}")
    return {rec.id: str(rec.seq) for rec in SeqIO.parse(str(path), "fasta")}


def load_plddt_from_pdb(path: Path) -> List[float]:
    plddt_by_pos: Dict[int, float] = {}
    with path.open("r", encoding="utf-8") as handle:
        for line in handle:
            if not line.startswith("ATOM"):
                continue
            if line[12:16].strip() != "CA":
                continue
            try:
                res_idx = int(line[22:26])
                plddt = float(line[60:66])
            except ValueError:
                continue
            plddt_by_pos[res_idx] = plddt
    if not plddt_by_pos:
        return []
    max_idx = max(plddt_by_pos)
    return [plddt_by_pos.get(i, np.nan) for i in range(1, max_idx + 1)]


def build_seed_dataframe(
    cfg: SeedConfig,
    ref_seq: str,
    domains: Dict[str, eda.Domain],
) -> Tuple[pd.DataFrame, int]:
    sequences = load_sequences(cfg.fasta_path)
    total_sequences = len(sequences)
    rows: List[Dict[str, float]] = []
    for pdb_name in sorted(cfg.pdb_dir.glob("*.pdb")):
        seq_id = pdb_name.stem
        seq = sequences.get(seq_id)
        if not seq:
            continue
        plddt = load_plddt_from_pdb(pdb_name)
        if not plddt:
            continue
        mapping = eda.align_ref_to_query(ref_seq, seq)
        entry: Dict[str, float] = {
            "seed": cfg.name,
            "id": seq_id,
            "len": float(len(seq)),
        }
        try:
            entry["total_mean_pLDDT"] = float(np.nanmean(plddt))
        except (ValueError, ZeroDivisionError):
            entry["total_mean_pLDDT"] = float("nan")
        for name, domain in domains.items():
            idx = [mapping[pos] for pos in range(domain.ref_start, domain.ref_end + 1) if pos in mapping]
            stats = eda.stats_for_indices(plddt, idx)
            entry[f"{name}_mean_pLDDT"] = float(stats["mean"]) if stats["mean"] is not None else float("nan")
        rows.append(entry)
    df = pd.DataFrame(rows)
    return df, total_sequences


def load_seq1_thresholds(path: Path) -> Dict[str, float]:
    thresholds: Dict[str, float] = {}
    with path.open("r", encoding="utf-8") as handle:
        reader = csv.DictReader(handle)
        for row in reader:
            metric = row.get("metric")
            val = row.get("seq1_threshold")
            if not metric or not val:
                continue
            try:
                thresholds[metric] = float(val)
            except ValueError:
                continue
    return thresholds


def main() -> None:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--ref-fasta",
        default=(
            "/home/eqk3/project_pi_mg269/eqk3/crisprData/atlas/generated_sequences/"
            "run-20250828-193254-ba4000-sweep/generations/ba4000/by-seed/seed1/step4_motif/anchor.faa"
        ),
        help="Reference FASTA used for domain mapping (expects a single sequence).",
    )
    parser.add_argument(
        "--domains",
        default="filtering/ESMfold_ranking/lb_domains.yaml",
        help="Domain definitions YAML/JSON consumed by esmfold_domain_assessor.py.",
    )
    parser.add_argument(
        "--thresholds",
        default="esmfold_seed_outputs/seq1_threshold_summary.csv",
        help="CSV supplying seq1 per-domain mean pLDDT thresholds.",
    )
    parser.add_argument(
        "--seed",
        action="append",
        default=[],
        help=(
            "Custom seed spec of the form name:/path/to/fasta:/path/to/pdb_dir. "
            "May be provided multiple times to add to the defaults."
        ),
    )
    parser.add_argument(
        "--skip-default-seeds",
        action="store_true",
        help="If set, only process seeds provided via --seed.",
    )
    parser.add_argument(
        "--output-prefix",
        default="metrics/esmfold_seed",
        help="Prefix (inside metrics/) used for the CSV report filenames.",
    )
    args = parser.parse_args()

    # Resolve seed configs
    seed_configs = {} if args.skip_default_seeds else dict(DEFAULT_SEEDS)
    seed_configs.update(parse_seed_specs(args.seed))
    if not seed_configs:
        raise SystemExit("No seeds specified; supply --seed or drop --skip-default-seeds.")

    # Load reference and domain definitions
    ref_records = list(SeqIO.parse(args.ref_fasta, "fasta"))
    if len(ref_records) != 1:
        raise SystemExit(f"Expected exactly one reference sequence in {args.ref_fasta}")
    ref_seq = str(ref_records[0].seq)
    _, domains = eda.load_domains(args.domains)

    thresholds = load_seq1_thresholds(Path(args.thresholds))
    metrics = ["total_mean_pLDDT"] + [f"{name}_mean_pLDDT" for name in domains.keys()]

    per_seed_frames: Dict[str, pd.DataFrame] = {}
    totals: Dict[str, int] = {}
    for seed_name, cfg in seed_configs.items():
        df, total_sequences = build_seed_dataframe(cfg, ref_seq, domains)
        per_seed_frames[seed_name] = df
        totals[seed_name] = total_sequences
        if not df.empty:
            out_path = cfg.pdb_dir.parent / f"esmfold_scores_{seed_name}_full.csv"
            df_out = df.rename(columns={"id": "id"})
            try:
                df_out.to_csv(out_path, index=False)
                print(f"[ok] wrote per-sequence scores: {out_path}")
            except Exception as exc:
                print(f"[warn] failed to write {out_path}: {exc}")

    if not per_seed_frames:
        raise SystemExit("No data collected from the provided seeds.")

    top_rows: List[Dict[str, object]] = []
    count_rows: List[Dict[str, object]] = []

    for seed_name, df in per_seed_frames.items():
        total_sequences = totals.get(seed_name, 0)
        processed_sequences = int(len(df))
        missing_pdb = total_sequences - processed_sequences if total_sequences else None

        if not df.empty:
            working = df.dropna(subset=["total_mean_pLDDT"])
        else:
            working = df
        if not working.empty:
            best = working.sort_values("total_mean_pLDDT", ascending=False).iloc[0]
            top_entry: Dict[str, object] = {
                "seed": seed_name,
                "top_id": best["id"],
                "top_len": int(best["len"]),
                "total_sequences_in_fasta": total_sequences,
                "processed_sequences": processed_sequences,
                "missing_pdb": missing_pdb,
                "top_total_mean_pLDDT": float(best["total_mean_pLDDT"]),
            }
            for domain_name in domains.keys():
                col = f"{domain_name}_mean_pLDDT"
                top_entry[f"top_{col}"] = float(best[col]) if col in best and pd.notna(best[col]) else np.nan
        else:
            top_entry = {
                "seed": seed_name,
                "top_id": None,
                "top_len": None,
                "total_sequences_in_fasta": total_sequences,
                "processed_sequences": processed_sequences,
                "missing_pdb": missing_pdb,
                "top_total_mean_pLDDT": np.nan,
            }
            for domain_name in domains.keys():
                top_entry[f"top_{domain_name}_mean_pLDDT"] = np.nan
        top_rows.append(top_entry)

        if not df.empty:
            for metric in metrics:
                if metric not in df.columns:
                    continue
                thr = thresholds.get(metric)
                if thr is None:
                    continue
                count = int((df[metric] > thr).sum())
                count_rows.append(
                    {
                        "seed": seed_name,
                        "metric": metric,
                        "seq1_threshold": thr,
                        "num_sequences_with_pdb": processed_sequences,
                        "total_sequences_in_fasta": total_sequences,
                        "missing_pdb": missing_pdb,
                        "num_above_seq1": count,
                    }
                )

    timestamp = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_prefix = Path(args.output_prefix)
    if not output_prefix.parent.exists():
        output_prefix.parent.mkdir(parents=True, exist_ok=True)

    top_df = pd.DataFrame(top_rows)
    top_path = output_prefix.parent / f"{output_prefix.name}_top_{timestamp}.csv"
    top_df.to_csv(top_path, index=False)

    counts_df = pd.DataFrame(count_rows)
    counts_path = output_prefix.parent / f"{output_prefix.name}_counts_{timestamp}.csv"
    counts_df.to_csv(counts_path, index=False)

    print(f"[ok] wrote top summary: {top_path}")
    print(f"[ok] wrote threshold counts: {counts_path}")


if __name__ == "__main__":
    main()
